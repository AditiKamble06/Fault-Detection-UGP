{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   faultNumber  simulationRun  sample  xmeas_1  xmeas_2  xmeas_3  xmeas_4  \\\n",
      "0            0            2.0      21  0.25673   3668.3   4510.3   9.3270   \n",
      "1            0            2.0      22  0.25728   3644.0   4482.8   9.3429   \n",
      "2            0            2.0      23  0.30579   3692.9   4515.2   9.2993   \n",
      "3            0            2.0      24  0.30538   3729.0   4512.3   9.3040   \n",
      "4            0            2.0      25  0.27300   3678.1   4517.3   9.2570   \n",
      "\n",
      "   xmeas_5  xmeas_6  xmeas_7  ...  xmeas_38  xmeas_39  xmeas_40  xmeas_41  \\\n",
      "0   26.645   42.457   2702.8  ...   0.84462   0.11533    53.435    43.598   \n",
      "1   26.699   42.166   2704.1  ...   0.84462   0.11533    53.435    43.598   \n",
      "2   26.911   42.110   2704.3  ...   0.84462   0.11533    53.435    43.598   \n",
      "3   26.702   42.511   2704.7  ...   0.84462   0.11533    53.435    43.598   \n",
      "4   26.836   42.018   2707.7  ...   0.84462   0.11533    53.435    43.598   \n",
      "\n",
      "    xmv_1      xmv_2   xmv_3   xmv_4   xmv_5  xmv_10  \n",
      "0  62.260  54.109762  25.195  62.105  21.872  40.220  \n",
      "1  62.680  54.109762  25.141  63.101  22.188  41.331  \n",
      "2  63.068  54.109762  30.283  61.538  22.238  40.438  \n",
      "3  62.446  54.109762  30.324  61.499  22.183  41.357  \n",
      "4  62.302  54.109762  26.451  63.040  22.605  40.912  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_path = 'modified_data_test.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistics Model \"Binary  Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9440110323089046\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      2820\n",
      "           1       0.94      1.00      0.97     47940\n",
      "\n",
      "    accuracy                           0.94     50760\n",
      "   macro avg       0.47      0.50      0.49     50760\n",
      "weighted avg       0.89      0.94      0.92     50760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Load training and testing data\n",
    "train_data = pd.read_csv('modified_data_train.csv')\n",
    "test_data  = pd.read_csv('modified_data_test.csv')\n",
    "\n",
    "# 2. Convert fault numbers to binary (0 = No Fault, 1 = Faulty)\n",
    "train_data['binary_fault'] = train_data['faultNumber'].apply(lambda x: 0 if x == 0 else 1)\n",
    "test_data['binary_fault'] = test_data['faultNumber'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "# 3. Drop non-predictive columns\n",
    "drop_cols = ['faultNumber', 'simulationRun', 'sample', 'binary_fault']\n",
    "\n",
    "# 4. Separate features (X) and target (y)\n",
    "X_train = train_data.drop(columns=drop_cols, errors='ignore')\n",
    "y_train = train_data['binary_fault']\n",
    "\n",
    "X_test = test_data.drop(columns=drop_cols, errors='ignore')\n",
    "y_test = test_data['binary_fault']\n",
    "\n",
    "# 5. Align columns: Keep only common features\n",
    "common_cols = sorted(list(set(X_train.columns).intersection(set(X_test.columns))))\n",
    "X_train = X_train[common_cols]\n",
    "X_test  = X_test[common_cols]\n",
    "\n",
    "# 6. Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# 7. Train Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 8. Make Predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 9. Evaluate the Model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistics Model for \"Multiclass Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.3854609929078014\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.04      0.06      2820\n",
      "           1       0.92      0.84      0.88      2820\n",
      "           2       0.94      0.84      0.89      2820\n",
      "           4       0.62      0.85      0.72      2820\n",
      "           5       0.12      0.19      0.14      2820\n",
      "           6       1.00      0.22      0.36      2820\n",
      "           7       1.00      0.85      0.92      2820\n",
      "           8       0.26      0.49      0.34      2820\n",
      "          10       0.19      0.12      0.15      2820\n",
      "          11       0.08      0.03      0.05      2820\n",
      "          12       0.14      0.26      0.18      2820\n",
      "          13       0.10      0.19      0.13      2820\n",
      "          14       0.08      0.04      0.05      2820\n",
      "          16       0.12      0.03      0.05      2820\n",
      "          17       0.69      0.70      0.69      2820\n",
      "          18       0.61      0.58      0.59      2820\n",
      "          19       0.08      0.04      0.05      2820\n",
      "          20       0.34      0.62      0.44      2820\n",
      "\n",
      "    accuracy                           0.39     50760\n",
      "   macro avg       0.41      0.39      0.37     50760\n",
      "weighted avg       0.41      0.39      0.37     50760\n",
      "\n",
      "The data point is Faulty  with Fault Number: 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\madhu\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# 1. Load your training and testing data\n",
    "train_data = pd.read_csv('modified_data_train.csv')\n",
    "test_data  = pd.read_csv('modified_data_test.csv')\n",
    "\n",
    "# 2. Identify columns to drop (non-predictive or target columns)\n",
    "drop_cols = ['faultNumber', 'simulationRun', 'sample']\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X_train = train_data.drop(columns=drop_cols, errors='ignore')\n",
    "y_train = train_data['faultNumber']\n",
    "\n",
    "X_test = test_data.drop(columns=drop_cols, errors='ignore')\n",
    "y_test = test_data['faultNumber']\n",
    "\n",
    "# 3. Find the intersection of columns so that train and test have the same features\n",
    "common_cols = sorted(list(set(X_train.columns).intersection(set(X_test.columns))))\n",
    "\n",
    "# Keep only the common columns in the same order\n",
    "X_train = X_train[common_cols]\n",
    "X_test  = X_test[common_cols]\n",
    "\n",
    "# 4. Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)\n",
    "\n",
    "# 5. Create and train the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 6. Evaluate on the test set\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Test Accuracy:', accuracy)\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "new_data = np.array([[12.5, 4.3, 18.6, 22.1, 7.9, 5.5, 16.2, 3.8, 11.9, 14.0,\n",
    "                      20.3, 9.8, 13.1, 17.5, 15.6, 19.2, 10.4, 6.7, 8.9, 12.3,\n",
    "                      11.5, 14.8, 16.9, 7.3, 9.5, 15.0, 18.2, 19.8, 13.9, 10.7,\n",
    "                      16.1, 12.2, 7.8, 14.4, 11.0, 13.7, 17.3, 14.6]])  \n",
    "\n",
    "# Scale data\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Predict\n",
    "fault_prediction = model.predict(new_data_scaled)\n",
    "\n",
    "# Result\n",
    "if fault_prediction[0] == 0:\n",
    "    print(\"The data point is Non-Faulty \")\n",
    "else:\n",
    "    print(f\"The data point is Faulty  with Fault Number: {fault_prediction[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes  \"Binary Classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Accuracy: 0.5521079590228526\n",
      "\n",
      "üìä Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      1.00      0.20      2820\n",
      "           1       1.00      0.53      0.69     47940\n",
      "\n",
      "    accuracy                           0.55     50760\n",
      "   macro avg       0.56      0.76      0.44     50760\n",
      "weighted avg       0.95      0.55      0.66     50760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the training and testing data\n",
    "train_data = pd.read_csv('modified_data_train.csv')\n",
    "test_data  = pd.read_csv('modified_data_test.csv')\n",
    "\n",
    "#  Convert fault numbers to binary (0 = No Fault, 1 = Faulty)\n",
    "train_data['binary_fault'] = train_data['faultNumber'].apply(lambda x: 0 if x == 0 else 1)\n",
    "test_data['binary_fault'] = test_data['faultNumber'].apply(lambda x: 0 if x == 0 else 1)\n",
    "\n",
    "#  Drop non-predictive columns\n",
    "drop_cols = ['faultNumber', 'simulationRun', 'sample']\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X_train = train_data.drop(columns=drop_cols + ['binary_fault'], errors='ignore')\n",
    "y_train = train_data['binary_fault']\n",
    "\n",
    "X_test = test_data.drop(columns=drop_cols + ['binary_fault'], errors='ignore')\n",
    "y_test = test_data['binary_fault']\n",
    "\n",
    "#  Align columns between train and test\n",
    "common_cols = sorted(list(set(X_train.columns).intersection(set(X_test.columns))))\n",
    "X_train = X_train[common_cols]\n",
    "X_test = X_test[common_cols]\n",
    "\n",
    "#  Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "#  Initialize and train Gaussian Naive Bayes\n",
    "model = GaussianNB()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "#  Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "#  Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"üîç Accuracy:\", accuracy)\n",
    "print(\"\\nüìä Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes  \"Multiclass\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "Best Hyperparameters: {'nb__var_smoothing': 1e-06}\n",
      "Test Accuracy: 0.5765957446808511\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.80      0.28      2820\n",
      "           1       0.95      0.82      0.88      2820\n",
      "           2       1.00      0.81      0.90      2820\n",
      "           4       0.94      0.83      0.88      2820\n",
      "           5       0.24      0.11      0.15      2820\n",
      "           6       1.00      0.79      0.88      2820\n",
      "           7       1.00      0.80      0.89      2820\n",
      "           8       0.70      0.48      0.57      2820\n",
      "          10       0.54      0.21      0.30      2820\n",
      "          11       0.66      0.66      0.66      2820\n",
      "          12       0.46      0.36      0.40      2820\n",
      "          13       0.76      0.54      0.63      2820\n",
      "          14       0.79      0.74      0.77      2820\n",
      "          16       0.36      0.20      0.26      2820\n",
      "          17       0.83      0.54      0.65      2820\n",
      "          18       0.56      0.62      0.59      2820\n",
      "          19       0.48      0.59      0.53      2820\n",
      "          20       0.67      0.49      0.56      2820\n",
      "\n",
      "    accuracy                           0.58     50760\n",
      "   macro avg       0.67      0.58      0.60     50760\n",
      "weighted avg       0.67      0.58      0.60     50760\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# 1. Load training and testing data\n",
    "train_data = pd.read_csv('modified_data_train.csv')\n",
    "test_data  = pd.read_csv('modified_data_test.csv')\n",
    "\n",
    "# 2. Define columns to drop (target and non-predictive columns)\n",
    "drop_cols = ['faultNumber', 'simulationRun', 'sample']\n",
    "\n",
    "# 3. Separate features and target\n",
    "X_train = train_data.drop(columns=drop_cols, errors='ignore')\n",
    "y_train = train_data['faultNumber']\n",
    "\n",
    "X_test = test_data.drop(columns=drop_cols, errors='ignore')\n",
    "y_test = test_data['faultNumber']\n",
    "\n",
    "# 4. Align columns: select only common features in both train and test\n",
    "common_cols = sorted(set(X_train.columns).intersection(set(X_test.columns)))\n",
    "X_train = X_train[common_cols]\n",
    "X_test  = X_test[common_cols]\n",
    "\n",
    "# 5. Create a Pipeline with StandardScaler and GaussianNB\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('nb', GaussianNB())\n",
    "])\n",
    "\n",
    "# 6. Define hyperparameter grid for GaussianNB\n",
    "param_grid = {\n",
    "    'nb__var_smoothing': [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "# 7. Use GridSearchCV to find the best hyperparameters with 5-fold CV\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='accuracy',  # You can choose other metrics like 'f1_macro'\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 8. Fit grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# 9. Get the best model and evaluate on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
